{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75208b23",
   "metadata": {},
   "source": [
    "# TechBairn Project-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69230f5b",
   "metadata": {},
   "source": [
    "Made by: Rishabhraj Srivastava"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e49d8",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4479574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5260306",
   "metadata": {},
   "source": [
    "### Defining the Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a91e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # The number of images in each batch\n",
    "num_epochs = 10 # The number of times to train on the whole dataset\n",
    "learning_rate = 0.01 # The learning rate for the optimizer\n",
    "num_classes = 2 # The number of classes (apple or banana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ce2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for the images\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(224), # Resize the images to 224 x 224 pixels\n",
    "     transforms.ToTensor(), # Convert the images to tensors\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Normalize the images\n",
    "\n",
    "# Load the training and testing datasets from the folders\n",
    "trainset = torchvision.datasets.ImageFolder(root='/Users/rishabhrajsrivastava/Fruit-Images-Dataset/Training', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='/Users/rishabhrajsrivastava/Fruit-Images-Dataset/Test', transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    "\n",
    "# Define the classes (Apple and Banana)\n",
    "classes = ('Apple', 'Banana')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674ed699",
   "metadata": {},
   "source": [
    "### Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9544dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model using PyTorch\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3) # Input channels: 3, Output channels: 16, Kernel size: 3\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3) # Input channels: 16, Output channels: 32, Kernel size: 3\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, 3) # Input channels: 32, Output channels: 64, Kernel size: 3\n",
    "        # Pooling layer\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2) # Kernel size: 2, Stride: 2\n",
    "        # Fully connected layers\n",
    "        self.fc1 = torch.nn.Linear(64 * 26 * 26, 256) # Input features: 64 * 26 * 26, Output features: 256\n",
    "        self.fc2 = torch.nn.Linear(256, num_classes) # Input features: 256, Output features: num_classes\n",
    "        # Dropout layer\n",
    "        self.dropout = torch.nn.Dropout(0.2) # Dropout probability: 0.2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional layers with ReLU activation and pooling\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv3(x)))\n",
    "        # Flatten the output of the last convolutional layer\n",
    "        x = x.view(-1, 64 * 26 * 26)\n",
    "        # Apply the dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Apply the first fully connected layer with ReLU activation\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        # Apply the dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Apply the second fully connected layer with softmax activation\n",
    "        x = torch.nn.functional.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de379037",
   "metadata": {},
   "source": [
    "### Creating an Instance, Training and Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "814ed849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Saved Model\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the CNN model\n",
    "model = CNN()\n",
    "\n",
    "# Define the loss function (cross entropy loss)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0 # The running loss for each epoch\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data # Get the inputs and labels from the data\n",
    "        optimizer.zero_grad() # Zero the parameter gradients\n",
    "        outputs = model(inputs) # Forward pass the inputs through the model\n",
    "        loss = criterion(outputs, labels) # Calculate the loss\n",
    "        loss.backward() # Backward pass the loss through the model\n",
    "        optimizer.step() # Update the parameters with the optimizer\n",
    "\n",
    "        running_loss += loss.item() # Add the loss to the running loss\n",
    "\n",
    "        if i % 200 == 199: # Print the statistics every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model, 'model.pth')\n",
    "print('Saved Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be42b5",
   "metadata": {},
   "source": [
    "### Testing Model Based upon the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "800d4525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 100 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the testing dataset\n",
    "correct = 0 # The number of correct predictions\n",
    "total = 0 # The total number of predictions\n",
    "with torch.no_grad(): # No need to calculate the gradients\n",
    "    for data in testloader:\n",
    "        images, labels = data # Get the images and labels from the data\n",
    "        outputs = model(images) # Forward pass the images through the model\n",
    "        _, predicted = torch.max(outputs.data, 1) # Get the predicted class with the maximum probability\n",
    "        total += labels.size(0) # Add the number of labels to the total\n",
    "        correct += (predicted == labels).sum().item() # Add the number of correct predictions to the correct\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e5423",
   "metadata": {},
   "source": [
    "### Training Accuracy of each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53586baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Apple : 100 %\n",
      "Accuracy of Banana : 100 %\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy for each class\n",
    "class_correct = list(0. for i in range(num_classes)) # The number of correct predictions for each class\n",
    "class_total = list(0. for i in range(num_classes)) # The total number of predictions for each class\n",
    "with torch.no_grad(): # No need to calculate the gradients\n",
    "    for data in testloader:\n",
    "        images, labels = data # Get the images and labels from the data\n",
    "        outputs = model(images) # Forward pass the images through the model\n",
    "        _, predicted = torch.max(outputs, 1) # Get the predicted class with the maximum probability\n",
    "        c = (predicted == labels).squeeze() # Get a tensor of 0s and 1s indicating the correctness of each prediction\n",
    "        for i in range(min(batch_size, len(labels))): # Loop over each image in the batch\n",
    "            label = labels[i] # Get the label of the image\n",
    "            class_correct[label] += c[i].item() # Add the correctness to the class_correct list\n",
    "            class_total[label] += 1 # Add one to the class_total list\n",
    "\n",
    "for i in range(num_classes): # Loop over each class\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1235be2d",
   "metadata": {},
   "source": [
    "### Classifying the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import PIL # For loading and processing images\n",
    "import numpy as np # For converting images to arrays\n",
    "\n",
    "# Load the model\n",
    "model = torch.load('model.pth')\n",
    "print('Loaded Model')\n",
    "\n",
    "# Define a function to take an image as input and classify it\n",
    "def classify_image(image_path):\n",
    "    # Load the image from the path\n",
    "    image = PIL.Image.open(image_path)\n",
    "    # Apply the same transformations as the training and testing datasets\n",
    "    image = transform(image)\n",
    "    # Add a batch dimension to the image tensor\n",
    "    image = image.unsqueeze(0)\n",
    "    # Forward pass the image through the model\n",
    "    output = model(image)\n",
    "    # Get the predicted class with the maximum probability\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    # Get the class name from the classes list\n",
    "    class_name = classes[predicted.item()]\n",
    "    # Print the result\n",
    "    print('The image is classified as:', class_name)\n",
    "\n",
    "# Test the function with an example image\n",
    "classify_image('example.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cffa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fc77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
